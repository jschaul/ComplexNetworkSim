.. _more:

Scalability testing & further information
=========================================

.. _scalability:

Performance: How scalable is the simulation environment?
--------------------------------------------------------

The simulation environment can simulate processes for a varying number
of nodes in a graph, depending on how complex agent behaviour is. It is
important to note that performance depends on the number of events
triggered during the simulation, and how complex these events are, not
the number of agents. But the number of agents does also affect
performance due to the memory required for simulating agent behaviour.
From a few empirical tests detailed below, it can generally be assumed that **simulations run in under
one minute for up to a few thousand agents in a network** . The table
below gives performance results for different numbers of nodes in the network, both using the same easy agent behaviour.

    .. figure:: figures/scalability.png

    Performance of simulations. Times are in seconds, given as a guideline.
    (Measurements performed on a computer running Linux openSUSE 11.3 on Intel Q6600 Quad 2.4GHz with 4GB RAM.)

On complete graphs, each susceptible agent has to check for
every other agent in the network whether that agent is infected, which
makes the simulation slower than for scale-free networks. Here, a single
simulation takes time in the same order of magnitude than the creation
of a complete graph itself (using networkX).

On scale-free networks, the number of edges is much lower, thus each
agent needs to perform fewer checks, and the bottle-neck of performance
is the graph generation itself, since a single simulation only takes
about 20% of the time of the generation of the scale-free graph. And the
generation of a scale-free graph is done within the NetworkX library, so
comparatively the simulation framework developed in this project is
fairly efficient as long as agent behaviour is simple.

Performance of visualisations are fairly constant in time because the
time taken to do file I/O time generally outweighs the time taken to
perform statistical calculations or plot drawing, except for very large
numbers of trials. In all tests performed during this project, animation
and plotting always completed in less than 20 seconds. Performance of
visualisation does depend on the number of time steps however, since an
image snapshot is produced for each time step.

Performance: can it be improved?
--------------------------------

So far the aim has not been to develop a framwork that is the most efficient for the greatest number of nodes; however it should be possible to extend the framework to allow for (at least partial) parellisation of processing across multiple processor cores or over a distributed network. A first step would be to incorporate something like "Parallel Python" - but that is future work for which I will wait for a demand first before putting effort in. So if you'd like to use this package on more than one processor at once, send me an email and I'll put this future work higher up on my ToDo list.

Acknowledgements
----------------

Special thanks to `Dr. Mirco Musolesi`_, my supervisor during the creation of this project in the scope of a senior honours project in 4th year Computer Science at the `University of St Andrews`_. The framework, along with the analysis of some use case simulations was created in 2010-2011, and afterwards it was suggested to publish the framework code online as an open source project. It is released under a freeBSD license, so you may do with it what you want :)

Contact information
-------------------

My name is Jo√© Schaul, and my email address is <first name without the accent on the e> dot <last name> @gmail.com
Feel free to send me an email for any questions and comments. This is my first project so I'd appreciate some feedback on it. :)

.. _`Dr. Mirco Musolesi`: http://www.cs.bham.ac.uk/~musolesm
.. _`University of St Andrews`: http://www.st-andrews.ac.uk

